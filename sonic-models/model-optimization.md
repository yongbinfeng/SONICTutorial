---
description: documents on how to optimize the model deployments
---

# Model optimization

Triton offers a lot of nice ways to better utilize the coprocessors (in our case probably GPUs), such as dynamic batching, concurrent model executions, TensorRT optimizations, etc. &#x20;
